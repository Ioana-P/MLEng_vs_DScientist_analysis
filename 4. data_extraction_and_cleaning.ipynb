{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=contents></a>\n",
    "\n",
    "# Extraction and cleaning notebook\n",
    "## Data retrieved from glassdoor.com\n",
    "\n",
    "Data was extracted via Glassdoor's REST API (documentation here: https://www.glassdoor.com/developer/index.htm). \n",
    "\n",
    "[0. Data extraction via Selenium scraping](#api)\n",
    "\n",
    "[1. Data Inspection](#insp)\n",
    "\n",
    "[2. Cleaning numerical data](#numerical)\n",
    "\n",
    "[3. Cleaning categorical data](#categ)\n",
    "\n",
    "[4. Cleaning text data](#text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests as req\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import selenium as sl\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "tokenizer = RegexpTokenizer(r'\\b\\w{3,}\\b')\n",
    "stop_words = list(set(stopwords.words(\"english\")))\n",
    "stop_words += list(string.punctuation)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=api ><a/> \n",
    "\n",
    "## 0. Data Extraction via Selenium scraping\n",
    "    \n",
    "[LINK to table of contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class APICaller:\n",
    "    def __init__(self, base_url, token=None, ignore_token=True):\n",
    "        self.token = os.getenv('TOKEN')\n",
    "        if ignore_token==False:\n",
    "            if len(self.token) == 0:\n",
    "                raise ValueError('Missing API token!')\n",
    "        self.base_url=base_url\n",
    "        \n",
    "    def retrieve_one(self,url_extension,location=None, date=None, date1=None):  \n",
    "        if date1!=None:\n",
    "            response = req.get(self.base_url+url_extension+f'{location}/StartDate={date}/EndDate={date1}/Json').json()\n",
    "        elif (date!=None and date1==None):\n",
    "            response = req.get(self.base_url+url_extension+f'{location}/Date={date}/Json').json()\n",
    "        else:\n",
    "            print(self.base_url+url_extension)\n",
    "            response = req.get(self.base_url+url_extension).json()\n",
    "        return response\n",
    "    \n",
    "    \n",
    "    def retrieve_many(self,location_list, date_list, var, limit):\n",
    "        data = []\n",
    "        counter=0\n",
    "        for location in location_list:\n",
    "            for date in date_list:\n",
    "                if counter==limit-1:\n",
    "                    time.sleep(60)\n",
    "                response = req.get(f'{self.url}/{key}/{location}/{date}/{var}').json()\n",
    "                data.append(response)\n",
    "                counter+=1\n",
    "        data_df = pd.read_json(data)    \n",
    "        return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://www.glassdoor.com/index.htm'>powered by <img src='https://www.glassdoor.com/static/img/api/glassdoor_logo_80.png' title='Job Search' /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/ipreoteasa/Desktop/Io/chromedriver_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.glassdoor.co.uk/'\n",
    "# ext_job = 'Job/london-data-scientist-jobs-SRCH_IL.0,6_IC2671300_KO7,21.htm?'\n",
    "ext_type = 'Job/'\n",
    "ext_search_loc = 'london-'\n",
    "ext_job_title = 'data-scientist-'\n",
    "ext_end = 'jobs-SRCH_IL.0,6_IC2671300_KO7,21.htm?'\n",
    "\n",
    "driver.get(base_url+ext_type+ext_search_loc+ext_job_title+ext_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f5c8cb4546ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# getting a job descr by xpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjobdescr_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/html/body/div[3]/div/div/div/div[1]/div/div/div[4]/div/div/div/div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# _xpath('//*[@id=\"Comment_5561090\"]/div/div[2]/div[1]/span[1]/a[2]')[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# getting a job descr by xpath\n",
    "\n",
    "jobdescr_element = driver.find_elements_by_xpath('/html/body/div[3]/div/div/div/div[1]/div/div/div[4]/div/div/div/div')[0]\n",
    "\n",
    "# _xpath('//*[@id=\"Comment_5561090\"]/div/div[2]/div[1]/span[1]/a[2]')[0]\n",
    "\n",
    "\n",
    "jobdescr = jobdescr_element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are looking for Data Scientists who are interested in using data to draw insights that will result in policy changes or business process optimisation, benefiting the public. The applicant will be scoping projects with stakeholders, using data sets across Government Agencies, applying business acumen to tease out relevant impactful insights, and presenting insights in a clear, concise manner by using appropriate visualisations.\\n\\nHe/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation. He/she should also be comfortable with engaging stakeholders on sharpening their business problems.\\n\\nThe analytics work that we do are typically action oriented and cross-cutting across various domains such as social, economic and infrastructure sectors. Over time, he/she will gain exposure to various policy and ops domains and become more adept in bridging between business users and technical expertise.\\n\\nWhat to Expect:\\nWork closely with stakeholders to understand their business challenges, scope the problem and develop business case on how to turn data into critical information and knowledge that are actionable and impactful,.\\nPerform data cleaning, pre-processing, feature engineering and build relevant models to conduct meaningful analysis. Apply appropriate visualisation techniques to communicate the insight effectively. Iterate with the stakeholders to perform subsequent deep dives based on the initial insights.\\nDepending on the use case, design of dashboards and interactive visualisations as tools for data exploration and storytelling may be expected.\\nPotentially deployed to other Government Agencies to be their resident Data Scientist. This will involve formulating and implementing strategies to build strong pipeline of impactful projects at the Agency and executing these projects.\\nHow to Succeed:\\n\\nBachelor Degree in Computer Science, Statistics, Economics, Quantitative Social Science, or related degrees. Advanced degrees preferred. We will also factor in relevant certifications (e.g., Coursera)\\nMinimum 2 years of relevant working experience, preferably in public sector or data science field\\nAbility to take a broad, strategic perspective as well as drill deep to understand business needs and challenges\\nUnderstand key concepts, techniques and considerations in machine learning and data analytics\\nTraining and relevant experience in one or more of the following areas:\\nData science tools such as R, Python\\nVisual analytics technologies like Tableau, Qlik\\nExcellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders\\nStrong analytical, conceptualisation and problem solving skills\\nTeam player with strong organization and people handling skills\\nPassion for the use of analytics and data to improve Public Service'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobdescr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so far so good, accessing the correct data. Now to turn to pagination and getting other resuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.glassdoor.co.uk/Job/london-data-scientist-jobs-SRCH_IL.0,6_IC2671300_KO7,21.htm?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.current_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.glassdoor.co.uk/'\n",
    "ext_type = 'Job/'\n",
    "ext_search_loc = 'london-'\n",
    "ext_job_title = 'data-scientist-'\n",
    "ext_end = 'jobs-SRCH_IL.0,6_IC2671300_KO7,21.htm?'\n",
    "\n",
    "# driver.get(base_url+ext_type+ext_search_loc+ext_job_title+ext_end)\n",
    "\n",
    "def job_POST_scraper(base_url = base_url, ext_search_type=ext_type,\n",
    "               ext_search_location = ext_search_loc, \n",
    "               ext_job_title = ext_job_title, \n",
    "               ext_end = ext_end, \n",
    "               num_job_descr=10):\n",
    "    \n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "#     options.add_argument('headless')\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/ipreoteasa/Desktop/Io/chromedriver_2',\n",
    "                             options=options)\n",
    "    driver.get(base_url+ext_type+ext_search_loc+ext_job_title+ext_end)\n",
    "\n",
    "\n",
    "    job_links = []\n",
    "       \n",
    "    while len(job_hrefs_list)<num_job_descr:\n",
    "        time.sleep(4)\n",
    "        try: \n",
    "            driver.find_element_by_class_name(\"selected\").click()\n",
    "        except ElementClickInterceptedException:\n",
    "            pass\n",
    "\n",
    "        time.sleep(.1)\n",
    "        # need to add a loop and a way to paginate through the next few jobs\n",
    "#         job_column = driver.find_element_by_class_name(\"jlGrid hover\")\n",
    "# #         print(job_column.text)\n",
    "#         job_hrefs_list = set([job_square.get_attribute('href') for job_square in job_column])# access the href element within the pages\n",
    "        #get the driver to get the URL you've saved\n",
    "        \n",
    "        elems = driver.find_elements_by_xpath(\"//*[@id='MainCol']/div[1]/ul\")\n",
    "        for elem in elems:\n",
    "            print(elem.get_attribute(\"href\"))\n",
    "            job_links.append(elem.text)\n",
    "        \n",
    "        \n",
    "        time.sleep(5)\n",
    "#         job_links = job_hrefs_list.text\n",
    "#         print(job_links)\n",
    "    return job_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking for Data Scientists who are interested in using data to draw insights that will result in policy changes or business process optimisation, benefiting the public. The applicant will be scoping projects with stakeholders, using data sets across Government Agencies, applying business acumen to tease out relevant impactful insights, and presenting insights in a clear, concise manner by using appropriate visualisations.\n",
      "\n",
      "He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation. He/she should also be comfortable with engaging stakeholders on sharpening their business problems.\n",
      "\n",
      "The analytics work that we do are typically action oriented and cross-cutting across various domains such as social, economic and infrastructure sectors. Over time, he/she will gain exposure to various policy and ops domains and become more adept in bridging between business users and technical expertise.\n",
      "\n",
      "What to Expect:\n",
      "Work closely with stakeholders to understand their business challenges, scope the problem and develop business case on how to turn data into critical information and knowledge that are actionable and impactful,.\n",
      "Perform data cleaning, pre-processing, feature engineering and build relevant models to conduct meaningful analysis. Apply appropriate visualisation techniques to communicate the insight effectively. Iterate with the stakeholders to perform subsequent deep dives based on the initial insights.\n",
      "Depending on the use case, design of dashboards and interactive visualisations as tools for data exploration and storytelling may be expected.\n",
      "Potentially deployed to other Government Agencies to be their resident Data Scientist. This will involve formulating and implementing strategies to build strong pipeline of impactful projects at the Agency and executing these projects.\n",
      "How to Succeed:\n",
      "\n",
      "Bachelor Degree in Computer Science, Statistics, Economics, Quantitative Social Science, or related degrees. Advanced degrees preferred. We will also factor in relevant certifications (e.g., Coursera)\n",
      "Minimum 2 years of relevant working experience, preferably in public sector or data science field\n",
      "Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges\n",
      "Understand key concepts, techniques and considerations in machine learning and data analytics\n",
      "Training and relevant experience in one or more of the following areas:\n",
      "Data science tools such as R, Python\n",
      "Visual analytics technologies like Tableau, Qlik\n",
      "Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders\n",
      "Strong analytical, conceptualisation and problem solving skills\n",
      "Team player with strong organization and people handling skills\n",
      "Passion for the use of analytics and data to improve Public Service\n",
      "Apply Now: click Apply Now\n",
      "We are looking for Data Scientists who are interested in using data to draw insights that will result in policy changes or business process optimisation, benefiting the public. The applicant will be scoping projects with stakeholders, using data sets across Government Agencies, applying business acumen to tease out relevant impactful insights, and presenting insights in a clear, concise manner by using appropriate visualisations.\n",
      "\n",
      "He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation. He/she should also be comfortable with engaging stakeholders on sharpening their business problems.\n",
      "\n",
      "The analytics work that we do are typically action oriented and cross-cutting across various domains such as social, economic and infrastructure sectors. Over time, he/she will gain exposure to various policy and ops domains and become more adept in bridging between business users and technical expertise.\n",
      "\n",
      "What to Expect:\n",
      "Work closely with stakeholders to understand their business challenges, scope the problem and develop business case on how to turn data into critical information and knowledge that are actionable and impactful,.\n",
      "Perform data cleaning, pre-processing, feature engineering and build relevant models to conduct meaningful analysis. Apply appropriate visualisation techniques to communicate the insight effectively. Iterate with the stakeholders to perform subsequent deep dives based on the initial insights.\n",
      "Depending on the use case, design of dashboards and interactive visualisations as tools for data exploration and storytelling may be expected.\n",
      "Potentially deployed to other Government Agencies to be their resident Data Scientist. This will involve formulating and implementing strategies to build strong pipeline of impactful projects at the Agency and executing these projects.\n",
      "How to Succeed:\n",
      "\n",
      "Bachelor Degree in Computer Science, Statistics, Economics, Quantitative Social Science, or related degrees. Advanced degrees preferred. We will also factor in relevant certifications (e.g., Coursera)\n",
      "Minimum 2 years of relevant working experience, preferably in public sector or data science field\n",
      "Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges\n",
      "Understand key concepts, techniques and considerations in machine learning and data analytics\n",
      "Training and relevant experience in one or more of the following areas:\n",
      "Data science tools such as R, Python\n",
      "Visual analytics technologies like Tableau, Qlik\n",
      "Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders\n",
      "Strong analytical, conceptualisation and problem solving skills\n",
      "Team player with strong organization and people handling skills\n",
      "Passion for the use of analytics and data to improve Public Service\n",
      "Start your job application: click Apply Now\n",
      "We are looking for Data Scientists who are interested in using data to draw insights that will result in policy changes or business process optimisation, benefiting the public. The applicant will be scoping projects with stakeholders, using data sets across Government Agencies, applying business acumen to tease out relevant impactful insights, and presenting insights in a clear, concise manner by using appropriate visualisations.\n",
      "\n",
      "He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation. He/she should also be comfortable with engaging stakeholders on sharpening their business problems.\n",
      "\n",
      "The analytics work that we do are typically action oriented and cross-cutting across various domains such as social, economic and infrastructure sectors. Over time, he/she will gain exposure to various policy and ops domains and become more adept in bridging between business users and technical expertise.\n",
      "\n",
      "What to Expect:\n",
      "Work closely with stakeholders to understand their business challenges, scope the problem and develop business case on how to turn data into critical information and knowledge that are actionable and impactful,.\n",
      "Perform data cleaning, pre-processing, feature engineering and build relevant models to conduct meaningful analysis. Apply appropriate visualisation techniques to communicate the insight effectively. Iterate with the stakeholders to perform subsequent deep dives based on the initial insights.\n",
      "Depending on the use case, design of dashboards and interactive visualisations as tools for data exploration and storytelling may be expected.\n",
      "Potentially deployed to other Government Agencies to be their resident Data Scientist. This will involve formulating and implementing strategies to build strong pipeline of impactful projects at the Agency and executing these projects.\n",
      "How to Succeed:\n",
      "\n",
      "Bachelor Degree in Computer Science, Statistics, Economics, Quantitative Social Science, or related degrees. Advanced degrees preferred. We will also factor in relevant certifications (e.g., Coursera)\n",
      "Minimum 2 years of relevant working experience, preferably in public sector or data science field\n",
      "Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges\n",
      "Understand key concepts, techniques and considerations in machine learning and data analytics\n",
      "Training and relevant experience in one or more of the following areas:\n",
      "Data science tools such as R, Python\n",
      "Visual analytics technologies like Tableau, Qlik\n",
      "Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders\n",
      "Strong analytical, conceptualisation and problem solving skills\n",
      "Team player with strong organization and people handling skills\n",
      "Passion for the use of analytics and data to improve Public Service\n",
      "Apply Now: click Apply Now\n",
      "We are looking for Data Scientists who are interested in using data to draw insights that will result in policy changes or business process optimisation, benefiting the public. The applicant will be scoping projects with stakeholders, using data sets across Government Agencies, applying business acumen to tease out relevant impactful insights, and presenting insights in a clear, concise manner by using appropriate visualisations.\n",
      "\n",
      "He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation. He/she should also be comfortable with engaging stakeholders on sharpening their business problems.\n",
      "\n",
      "The analytics work that we do are typically action oriented and cross-cutting across various domains such as social, economic and infrastructure sectors. Over time, he/she will gain exposure to various policy and ops domains and become more adept in bridging between business users and technical expertise.\n",
      "\n",
      "What to Expect:\n",
      "Work closely with stakeholders to understand their business challenges, scope the problem and develop business case on how to turn data into critical information and knowledge that are actionable and impactful,.\n",
      "Perform data cleaning, pre-processing, feature engineering and build relevant models to conduct meaningful analysis. Apply appropriate visualisation techniques to communicate the insight effectively. Iterate with the stakeholders to perform subsequent deep dives based on the initial insights.\n",
      "Depending on the use case, design of dashboards and interactive visualisations as tools for data exploration and storytelling may be expected.\n",
      "Potentially deployed to other Government Agencies to be their resident Data Scientist. This will involve formulating and implementing strategies to build strong pipeline of impactful projects at the Agency and executing these projects.\n",
      "How to Succeed:\n",
      "\n",
      "Bachelor Degree in Computer Science, Statistics, Economics, Quantitative Social Science, or related degrees. Advanced degrees preferred. We will also factor in relevant certifications (e.g., Coursera)\n",
      "Minimum 2 years of relevant working experience, preferably in public sector or data science field\n",
      "Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges\n",
      "Understand key concepts, techniques and considerations in machine learning and data analytics\n",
      "Training and relevant experience in one or more of the following areas:\n",
      "Data science tools such as R, Python\n",
      "Visual analytics technologies like Tableau, Qlik\n",
      "Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders\n",
      "Strong analytical, conceptualisation and problem solving skills\n",
      "Team player with strong organization and people handling skills\n",
      "Passion for the use of analytics and data to improve Public Service\n",
      "Apply Now: click Apply Now\n",
      "We are looking for Data Scientists who are interested in using data to draw insights that will result in policy changes or business process optimisation, benefiting the public. The applicant will be scoping projects with stakeholders, using data sets across Government Agencies, applying business acumen to tease out relevant impactful insights, and presenting insights in a clear, concise manner by using appropriate visualisations.\n",
      "\n",
      "He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation. He/she should also be comfortable with engaging stakeholders on sharpening their business problems.\n",
      "\n",
      "The analytics work that we do are typically action oriented and cross-cutting across various domains such as social, economic and infrastructure sectors. Over time, he/she will gain exposure to various policy and ops domains and become more adept in bridging between business users and technical expertise.\n",
      "\n",
      "What to Expect:\n",
      "Work closely with stakeholders to understand their business challenges, scope the problem and develop business case on how to turn data into critical information and knowledge that are actionable and impactful,.\n",
      "Perform data cleaning, pre-processing, feature engineering and build relevant models to conduct meaningful analysis. Apply appropriate visualisation techniques to communicate the insight effectively. Iterate with the stakeholders to perform subsequent deep dives based on the initial insights.\n",
      "Depending on the use case, design of dashboards and interactive visualisations as tools for data exploration and storytelling may be expected.\n",
      "Potentially deployed to other Government Agencies to be their resident Data Scientist. This will involve formulating and implementing strategies to build strong pipeline of impactful projects at the Agency and executing these projects.\n",
      "How to Succeed:\n",
      "\n",
      "Bachelor Degree in Computer Science, Statistics, Economics, Quantitative Social Science, or related degrees. Advanced degrees preferred. We will also factor in relevant certifications (e.g., Coursera)\n",
      "Minimum 2 years of relevant working experience, preferably in public sector or data science field\n",
      "Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges\n",
      "Understand key concepts, techniques and considerations in machine learning and data analytics\n",
      "Training and relevant experience in one or more of the following areas:\n",
      "Data science tools such as R, Python\n",
      "Visual analytics technologies like Tableau, Qlik\n",
      "Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders\n",
      "Strong analytical, conceptualisation and problem solving skills\n",
      "Team player with strong organization and people handling skills\n",
      "Passion for the use of analytics and data to improve Public Service\n",
      "Apply Now: click Apply Now\n"
     ]
    }
   ],
   "source": [
    "job_link_list = job_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_individual_job_posts():\n",
    "    \"\"\"Function that takes in list of job post links and scrapes the descriptions off\"\"\"\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "descr_list = []    \n",
    "    \n",
    "for link in job_link_list:\n",
    "    descr_list.append(scrape_individual_job_posts(link=link))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=insp ><a/> \n",
    "\n",
    "## 1. Data Inspection\n",
    "    \n",
    "[LINK to table of contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=numerical ><a/> \n",
    "\n",
    "## 2. Cleaning numerical data\n",
    "    \n",
    "[LINK to table of contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=categ ><a/> \n",
    "\n",
    "## 3. Cleaning categorical data\n",
    "   \n",
    "[LINK to table of contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=text ><a/> \n",
    "\n",
    "## 4. Cleaning text data\n",
    "    \n",
    "[LINK to table of contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
